inline fn __red16(reg u512 r rv const_q) -> reg u512
{
  reg u512 tmp;
  tmp = #VPMULH_32u16(rv, r);
  tmp = #VPSRA_32u16(tmp, 10);
  tmp = #VPMULL_32u16(tmp, const_q);
  r = #VPSUB_32u16(r, tmp);
  return r;

} 
inline fn __montmul(reg u512 zeta zetaqinv const_q r) -> reg u512 
{
  reg u512 tmp tmp1;
  tmp = #VPMULH_32u16(r, zeta);
  tmp1 = #VPMULL_32u16(r, zetaqinv);
  tmp1 = #VPMULH_32u16(r, const_q);
  r = #VPSUB_32u16(tmp, tmp1);
  return r;
}
inline fn __fqmulx32(reg u512 a b qx32 qinvx32) -> reg u512
{
  reg u512 rd rhi rlo;
  rhi = #VPMULH_32u16(a, b);
  rlo = #VPMULH_32u16(a, b);
  rlo = #VPMULL_32u16(rlo, qinvx32);
  rlo = #VPMULH_32u16(rlo, qx32);
  rd = #VPSUB_32u16(rhi, rlo);

  return rd;
}

inline
fn mont_red(reg u512 lo hi qx32 qinvx32) -> reg u512 {
  reg u512 m;

  m  = #VPMULL_32u16(lo, qinvx32);
  m  = #VPMULH_32u16(m, qx32);
  lo = #VPSUB_32u16(hi, m);

  return lo;
}

inline 
fn __csubq(reg u512 r qx16) -> reg u512
{
  reg u512 t;
  r = #VPSUB_32u16(r, qx16);
  t = #VPSRA_32u16(r, 15);
  t = #VPAND_512(t, qx16);
  r = #VPADD_32u16(t, r);
  return r;
}